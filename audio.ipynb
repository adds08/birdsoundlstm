{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "### **Flowchart**\n",
    "<div style=\"text-align:'center';\">\n",
    "<img src=\"./flowchart.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "### **Explanation**\n",
    "In this particular process we need to firstly load the data. The data is downloaded locally and is put in path *'/charaNet'*. This dataset was downloaded from Kaggle and it's source is linked at the end of this paper.\n",
    "\n",
    "We defined three directories, each for test, train and validation set that has already been pre-defined from the data source. In this each of the folder contain sub folders which have name of the bird for whose audio are inside the respective folder.\n",
    "\n",
    "In the next step we define a function that will assist us to load and preprocess the data. Preprocessing data is important for two reasons:\n",
    "1. The data is in audio format but we want it to \n",
    "\n",
    "This function, `load_data(data_dir)`, is designed to load audio data from a specified directory. It takes the directory path `data_dir` as input. Within this directory, the function expects subdirectories, each representing a category or class of audio data. The function iterates through these subdirectories, loading each audio file found within them using the librosa library. It pads the audio data to ensure uniform length using `pad_sequences` from `sequence.data_utils`. The loaded audio data is appended to a list `X`, while corresponding labels are assigned based on the folder name and appended to a separate list `y`. Finally, it returns `X` and `y` as numpy arrays, where `X` contains the audio data and `y` contains the corresponding labels. Overall, this function facilitates the preprocessing and organization of audio data for machine learning tasks such as classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4325, 88200)\n",
      "y_train shape: (4325, 41)\n",
      "X_test shape: (1082, 88200)\n",
      "y_test shape: (1082, 41)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path to your data directory\n",
    "input_dir = './charaNet/train'\n",
    "test_dir = './charaNet/test'\n",
    "val_dir = './charaNet/val'\n",
    "\n",
    "# Define the sampling rate and duration of audio samples\n",
    "sampling_rate = 44100\n",
    "duration = 2  # Duration in seconds\n",
    "\n",
    "# Function to load audio files and their corresponding labels\n",
    "def load_data(data_dir):\n",
    "    X = []  # List to store audio data\n",
    "    y = []  # List to store corresponding labels\n",
    "    \n",
    "    # Iterate over the folders in your data directory\n",
    "    for label, category in enumerate(os.listdir(data_dir)):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(category_dir):\n",
    "            # Iterate over the files in the category directory\n",
    "            for file in os.listdir(category_dir):\n",
    "                file_path = os.path.join(category_dir, file)\n",
    "                \n",
    "                # Load audio data using librosa\n",
    "                audio_data, _ = librosa.load(file_path, sr=sampling_rate, duration=duration)\n",
    "                \n",
    "                # Pad audio data to ensure uniform length\n",
    "                audio_data = sequence.data_utils.pad_sequences([audio_data], maxlen=sampling_rate * duration, padding='post')[0]\n",
    "                \n",
    "                # Append the audio data to X\n",
    "                X.append(audio_data)\n",
    "                \n",
    "                # Assign the label based on the folder name\n",
    "                y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load data and labels\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "num_classes = len(np.unique(y))\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes for verification\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
